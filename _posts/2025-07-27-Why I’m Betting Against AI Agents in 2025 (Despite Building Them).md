---
layout: post
title: "Why Iâ€™m Betting Against AI Agents in 2025 (Despite Building Them)"
date: 2025-07-26
tags: [ç¬”è®°, ç”Ÿæ´»]
---

Original Post: [Why I'm Betting Against AI Agents in 2025 (Despite Building Them)](https://utkarshkanwat.com/writing/betting-against-agents/)

## ğŸš« Cutting Through the Hype

Utkarsh Kanwat, a handsâ€‘on AI engineer, has built **12+ productionâ€‘grade agent systems** across development, DevOps, data ops, CI/CD, and more. Despite this, he warns that 2025â€™s wave of **â€œfully autonomous AI agentsâ€** is fundamentally flawedâ€”the problems are mathematical, economic, and engineeringâ€‘level, not hype. ([Utkarsh Kanwat][1])

---

## 1. Error Compounding: The Reliability Gap

* If each agent step succeeds 95% of the time, a 20â€‘step chain yields only \~36% overall success.
* Production environments demand **99.9%+ reliability**, making multiâ€‘step autonomous workflows unviable.
* His agent systems prevent these failures by using **bounded contexts, rollback points, verifiable operations**, and **human decision gates** for critical steps. ([Utkarsh Kanwat][1])

A Reddit reader captures the engineerâ€™s skepticism succinctly:

> â€œ99.9% sounds impressive to a nonâ€‘engineer. But one in a thousand is not rare at all.â€ ([Reddit][2])

---

## 2. Token Economics: The Quadratic Cost Trap

* **Conversational agents** require reprocessing the entire context on every interaction.
* Token cost grows **quadratically with conversation length**, so long sessions become costâ€‘prohibitive (e.g., \$50â€“100 per session by 100 turns).
* Stateless agents (e.g. â€œspec â†’ function â†’ doneâ€) avoid this issueâ€”no context buildup, negligible token inflation. ([Utkarsh Kanwat][1])

The tradeoff is clear: economic viability favors narrowly scoped, stateless agents over interactive dialogues.

---

## 3. Tool Engineering: The Unseen Majority

* AI tooling demands **engineered interfaces** that handle partial failures, state changes, and recovery logic.
* Raw API outputs are **too noisy** or verboseâ€”agents need structured, compressed feedback to make correct decisions.
* Designing abstractions that report "10k rows returned, here are 5 examples" vs raw data requires effort.

According to Kanwat, **70% of the work** is in building these abstractionsâ€”not in model prompts. ([Utkarsh Kanwat][1])

---

## 4. Integration: The Enterprise Trap

* Real-world systems are messy: legacy APIs, varying auth flows, rate limits, inconsistent behaviors, permissions, and compliance demands.
* Kanwatâ€™s agents layer on **connection pooling**, **transaction management**, **timeout logic**, **audit logs**, and moreâ€”typical â€œagentâ€ solutions gloss over these.
* Integration complexity, he argues, is where most proposed autonomous agents fail in production. ([Utkarsh Kanwat][1])

---

## âœ… What *Actually* Works

Kanwat emphasizes that effective agents share these traits:

* **Human-in-the-loop at key points**: users review UI, approve destructive operations, or verify pull requests.
* **Clear scope and bounds**: a tool that does *one thing well*, like generating a React component or Terraform, then finishes. No chaining or state leakage.
* **Robust feedback and rollback mechanisms**: each operation is verifiable, auditable, and recoverable.
* **AI for generating intent or content**, traditional engineering for execution and safety. ([Utkarsh Kanwat][1])

---

## ğŸ›  Key Engineering Lessons

For engineers building or evaluating agentic systems:

| Principle                                | Summary                                                              |
| ---------------------------------------- | -------------------------------------------------------------------- |
| **Define boundaries**                    | Clearly scope agent responsibility; avoid chaining too many steps    |
| **Design for failure**                   | Include rollbacks and checkpoints                                    |
| **Mind token economics**                 | Stateless designs are cheaper and more reliable                      |
| **Prioritize reliability over autonomy** | Users trust consistent systems more than occasional magic            |
| **Build tooling layers**                 | Input filtering, state summarization, error feedbackâ€”engineered well |

---

## ğŸ”® Market & Organizational Outlook

* Ventureâ€‘backed startups promising full autonomy may struggle with scale and burn through capital.
* Enterprise vendors who bolt agents onto existing stacks will face **integration stagnation**.
* Winners will be teams building **specialized, constrained assistants**, not generalâ€‘purpose agent platforms. ([Utkarsh Kanwat][1])

The conclusion? The future lies in **hybrid models**â€”AI-driven productivity with engineering controls, not blind autonomy.

---

### ğŸ§  From a Computer Engineer Lens

* The article scratches below the surface: itâ€™s not about training bigger models, but about designing **software systems** that can use AI safely and efficiently.
* The real engineering challenge is about **workflow orchestration, feedback loops, observability, and cost control**.
* If you're building AIâ€‘powered tools, start with **clear module boundaries**, **statelessness where possible**, and **deterministic infrastructure scaffolding**.

---

### ğŸ’¬ Community Perspective

On Reddit:

> â€œThe compounding error problem is indeed realâ€¦ Most ideas fall apart before you get to 100.â€
> â€œThe ones reliable enough to make it into production are dumb. Not exciting at all.â€ ([Reddit][2])

---

### âœ… Final Summary

* **Not antiâ€‘AI**, but bullish on **rightâ€‘headed AI architecture**.
* Autonomous agents as hyped may be mathematically and economically infeasible.
* The successful pattern lies in **bounded scope, human oversight, engineered feedback loops**, and **traditional software reliability**.
* As you build, focus on **real world constraints**, not demos.

Let me know if youâ€™d like help translating any of these constraints into system architecture or code patterns!

[1]: https://utkarshkanwat.com/writing/betting-against-agents/?utm_source=chatgpt.com "Why I'm Betting Against AI Agents in 2025 (Despite Building Them)"
[2]: https://www.reddit.com/r/programming/comments/1m46lfb/why_im_betting_against_ai_agents_in_2025_despite/?utm_source=chatgpt.com "Why I'm Betting Against AI Agents in 2025 (Despite Building Them)"
